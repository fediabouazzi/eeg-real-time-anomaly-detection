
# eeg-real-time-anomaly-detection
Real-time seizure detection using EEG signals â€“ Kafka, Machine Learning, Streamlit, Docker

# ğŸš€ Real-Time Anomaly Detection Pipeline

ğŸ“¡ **Kafka + Python + ML + Streamlit + PostgreSQL + Docker Compose**

Ce projet simule et dÃ©tecte en temps rÃ©el des anomalies dans des donnÃ©es de capteurs. Il est conÃ§u pour apprendre les outils modernes utilisÃ©s en **data engineering**, **machine learning** et **monitoring temps rÃ©el**.

---

## ğŸ§± Architecture
```
(sensor_data.csv) â†’ [Trainer] â†’ model.pkl
                          â†“
                      Kafka â† producer
                          â†“
                  [Consumer] â†’ detect anomalies
                          â†“
           [CSV + PostgreSQL] â† Store anomalies
                          â†“
                   [Streamlit] â† Dashboard live
```

---

## ğŸ›  Technologies utilisÃ©es
- **Kafka** : streaming temps rÃ©el
- **Scikit-learn (Isolation Forest)** : dÃ©tection dâ€™anomalies
- **Streamlit** : visualisation & alertes
- **PostgreSQL** : base de donnÃ©es pour stockage persistant
- **Docker Compose** : orchestration de lâ€™architecture complÃ¨te

---

## ğŸ“ Structure du projet
```
â”œâ”€â”€ data_generator.py            # GÃ©nÃ¨re des donnÃ©es de capteurs (avec anomalies)
â”œâ”€â”€ kafka_producer.py           # Envoie les donnÃ©es dans Kafka
â”œâ”€â”€ kafka_real_time_detector.py # DÃ©tection dâ€™anomalies en direct (consumer)
â”œâ”€â”€ init_model.py               # EntraÃ®ne et sauvegarde le modÃ¨le Isolation Forest
â”œâ”€â”€ preprocessing.py            # Nettoyage et mise en forme des donnÃ©es
â”œâ”€â”€ streamlit_anomaly_dashboard.py # Dashboard local
â”œâ”€â”€ realtime_anomaly_log.csv    # Historique des anomalies dÃ©tectÃ©es
â”œâ”€â”€ Dockerfile.*                # 3 images : trainer, consumer, streamlit
â”œâ”€â”€ docker-compose.yml          # Lance toute l'architecture
â”œâ”€â”€ Makefile                    # Commandes utiles
â””â”€â”€ hf_space/                   # Version Streamlit pour Hugging Face Spaces
```

---

## â–¶ï¸ Lancer le projet (local avec Docker Compose)
```bash
git clone <repo>
cd anomaly_detection_project
make up
```

ğŸŒ AccÃ©der au dashboard : [http://localhost:8501](http://localhost:8501)

---

## ğŸ§ª Tester lâ€™envoi de donnÃ©es + dÃ©tection automatique
```bash
make test
```

ğŸ“¬ Un email est envoyÃ© si une anomalie est dÃ©tectÃ©e (optionnel si SMTP configurÃ©).

---

## ğŸ›° DÃ©ployer sur Hugging Face Spaces
1. Aller sur [https://huggingface.co/spaces](https://huggingface.co/spaces)
2. CrÃ©er un Space (SDK : Streamlit)
3. Copier le dossier `hf_space/`
4. Lancer :
```bash
make sync-hf
```

---
## ğŸ” Configuration des variables sensibles

Le projet utilise un fichier `.env` pour stocker toutes les variables sensibles (base de donnÃ©es, Kafka, e-mail, etc.).

- Exemple :
```ini
POSTGRES_USER=admin
POSTGRES_PASSWORD=secret123
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
```

- Ne jamais commiter ce fichier `.env`. Il est dÃ©jÃ  ignorÃ© via `.gitignore`
- Un fichier `.env.example` est fourni comme modÃ¨le. Pour l'utiliser :
```bash
cp .env.example .env
```
Puis remplissez-le avec vos vraies informations.

Toutes les applications (Python, Docker Compose, Streamlit) chargeront automatiquement les variables dÃ©finies dans `.env`



## âœ… IdÃ©al pour apprendre Ã  :
- manipuler des flux de donnÃ©es
- intÃ©grer machine learning en production
- automatiser un pipeline avec Docker
- exposer des rÃ©sultats via un dashboard web
## ğŸ‘¤ RÃ©alisÃ© par Fedia BOUAZZI 
>>>>>>> ea78ea4 (Initial commit of EEG end-to-end anomaly detection project)
